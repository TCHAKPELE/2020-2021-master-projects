## My use case:

**Disclaimer**: In the following example, technical choices are probably not the best. But to poke all fonctionnality of Hasura I don't want to have complexity in the domain part. So I have chosen a simple use case.

I want to build a back office interface to manage a pool of question. I would like to provide various questions in my quizz game, so I need to frequently add new questions and delete others. In my case I want to rotate questions, a question could be publish(available in the game) or not publish. I also want to have a follow-up on questions statistic(currency, good/bad answer...). API calls will be secured by JWT token.

List of services I used:

- VueJs+TailwindCSS: to build a juicy web interface
- Firebase: used for authentification service and cloud function
- Postgres: used to store all questions
- Elastic: used to index questions and store statistic
- Hasura: used as API gateway

**Architecture schema:**

![Architecture schema](https://i.imgur.com/eal2ZuR.jpg)

**Hasura configuration:**

In this section I will explain how I configure Hasura to set up the architecture above, in the following explication I will use Hasura CLI to configure my Hasura instance, but it is also possible to make the same configuration with the web interface. I prefer to use CLI for automation and reusability. For some task I use the web interface because it's easier and faster than CLI, for these parts I will not go into the details of the web interface because it is very clear.

**1) Run Hasura with docker-compose:**

```yaml
hasura-graphql:
  image: hasura/graphql-engine:v1.3.3
  container_name: 'hasura_dev'
  ports:
    - '9100:8080'
  depends_on:
    - 'postgres'
  environment:
    HASURA_GRAPHQL_DATABASE_URL: postgres://postgres:postgrespassword@postgres:5432
```

Above you have the configuration of my Hasura container. For more details about container configuration you can consult the documentation:

[Run Hasura GraphQL engine using Docker | Hasura GraphQL Docs](https://hasura.io/docs/1.0/graphql/core/deployment/deployment-guides/docker.html#deployment-docker)

**2) Init Hasura CLI**

```bash
hasura init **--endpoint https://my-graphql-engine.com**
```

This command initializes a folder that contains all files needed to configure your Hasura instance, just need to specify your grahql endpoint. The generated folder could be stored where you want, alongside your front files for example.

**3) Build database schemas:**

**MPD of my data model:**

![MPD](https://i.imgur.com/cArmabz.png)

To build data model Hasura use to type of files:

**Migrations:**

Migrations files contain SQL script that builds tables, each migration represents a snapshot of the database. Throughout development the data model can evolve so you must use migrations to add, remove or delete tables. These files can be version controlled and can be used with your CI/CD system to make incremental updates.

**Metadata:**

Metadata is used to configure Hasura, here I need it to configure relationship between tables.

To build my data model I use Hasura console. Exist two ways to access to the console: by the url(http://hasura/console) or by launching it from CLI, the advantage if you are running it from CLI is that modifications applied will be automatically generated in the migrations/ directory and the metadata are exported in the metadata/ directory.

Launch from CLI:

```bash
hasura console
```

Generated files by operation in console:

**tables.yaml**:

```yaml
- table:
    schema: public
    name: QuestionAnswers
- table:
    schema: public
    name: QuestionCategories
- table:
    schema: public
    name: QuestionPropositions
  object_relationships:
    - name: Question
      using:
        foreign_key_constraint_on: QuestionId
- table:
    schema: public
    name: Questions
  object_relationships:
    - name: QuestionAnswer
      using:
        foreign_key_constraint_on: QuestionAnswerId
    - name: QuestionCategory
      using:
        foreign_key_constraint_on: QuestionCategorieId
  array_relationships:
    - name: QuestionPropositions
      using:
        foreign_key_constraint_on:
          column: QuestionId
          table:
            schema: public
            name: QuestionPropositions
```

**migrations/init/up.sql:**

```sql
CREATE TABLE public."QuestionAnswers" (
    "Id" integer NOT NULL,
    "Libelle" text
);
ALTER TABLE public."QuestionAnswers" ALTER COLUMN "Id" ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public."QuestionAnswers_Id_seq"
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public."QuestionCategories" (
    "Id" integer NOT NULL,
    "Libelle" text
);
ALTER TABLE public."QuestionCategories" ALTER COLUMN "Id" ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public."QuestionCategories_Id_seq"
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public."QuestionPropositions" (
    "Id" integer NOT NULL,
    "Libelle" text,
    "QuestionId" integer NOT NULL
);
ALTER TABLE public."QuestionPropositions" ALTER COLUMN "Id" ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public."QuestionPropositions_Id_seq"
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public."Questions" (
    "Id" integer NOT NULL,
    "Libelle" text,
    "QuestionCategorieId" integer NOT NULL,
    "QuestionAnswerId" integer NOT NULL
);
ALTER TABLE public."Questions" ALTER COLUMN "Id" ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public."Questions_Id_seq"
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public."__EFMigrationsHistory" (
    "MigrationId" character varying(150) NOT NULL,
    "ProductVersion" character varying(32) NOT NULL
);
ALTER TABLE ONLY public."QuestionAnswers"
    ADD CONSTRAINT "PK_QuestionAnswers" PRIMARY KEY ("Id");
ALTER TABLE ONLY public."QuestionCategories"
    ADD CONSTRAINT "PK_QuestionCategories" PRIMARY KEY ("Id");
ALTER TABLE ONLY public."QuestionPropositions"
    ADD CONSTRAINT "PK_QuestionPropositions" PRIMARY KEY ("Id");
ALTER TABLE ONLY public."Questions"
    ADD CONSTRAINT "PK_Questions" PRIMARY KEY ("Id");
ALTER TABLE ONLY public."__EFMigrationsHistory"
    ADD CONSTRAINT "PK___EFMigrationsHistory" PRIMARY KEY ("MigrationId");
CREATE INDEX "IX_QuestionPropositions_QuestionId" ON public."QuestionPropositions" USING btree ("QuestionId");
CREATE INDEX "IX_Questions_QuestionAnswerId" ON public."Questions" USING btree ("QuestionAnswerId");
CREATE INDEX "IX_Questions_QuestionCategorieId" ON public."Questions" USING btree ("QuestionCategorieId");
ALTER TABLE ONLY public."QuestionPropositions"
    ADD CONSTRAINT "FK_QuestionPropositions_Questions_QuestionId" FOREIGN KEY ("QuestionId") REFERENCES public."Questions"("Id") ON DELETE CASCADE;
ALTER TABLE ONLY public."Questions"
    ADD CONSTRAINT "FK_Questions_QuestionAnswers_QuestionAnswerId" FOREIGN KEY ("QuestionAnswerId") REFERENCES public."QuestionAnswers"("Id") ON DELETE CASCADE;
ALTER TABLE ONLY public."Questions"
    ADD CONSTRAINT "FK_Questions_QuestionCategories_QuestionCategorieId" FOREIGN KEY ("QuestionCategorieId") REFERENCES public."QuestionCategories"("Id") ON DELETE CASCADE;
```

For more details about data model update:

[Setting up Hasura migrations | Hasura GraphQL Docs](https://hasura.io/docs/1.0/graphql/core/migrations/migrations-setup.html)

**4) Add event trigger**

Now I need to add an event trigger on update field "isPublie" from "Questions" tables to call an endpoint who will index the concerned question in an Elasticsearch index, I did it using the web interface and the operations automatically edit **tables.yml:**

```yaml
- table:
    schema: public
    name: Questions
  object_relationships:
    - name: QuestionAnswer
      using:
        foreign_key_constraint_on: QuestionAnswerId
    - name: QuestionCategory
      using:
        foreign_key_constraint_on: QuestionCategorieId
  event_triggers:
    - name: indexQuestion
      definition:
        enable_manual: false
        update:
          columns:
            - IsPublie
      retry_conf:
        num_retries: 0
        interval_sec: 10
        timeout_sec: 60
      webhook: "http://indexation-api/indexquestion"**
  array_relationships:
    - name: QuestionPropositions
      using:
        foreign_key_constraint_on:
          column: QuestionId
          table:
            schema: public
            name: QuestionPropositions
```

Now each time "IsPublie" field will be modified a http request will be send to the webhook with a payload that contain lots of information and particularly the old and new value of the field.

[Event Triggers | Hasura GraphQL Docs](https://hasura.io/docs/1.0/graphql/core/event-triggers/index.html)

**5) Add authentication and authorization**

In my case I use JWT token for authentification and authorization. I need user account with credentials to log in my back office. Firebase provide authentication system to manage this case.

First step is to specify which token provider I will use to make Hasura able to verify token validity, in my case it's Google token service. To have all access in Hasura console it's usefull to specify an admint secret:

```yaml
hasura:
  image: hasura/graphql-engine:v1.3.3
  container_name: 'hasura_dev'
  ports:
    - '9100:8080'
  depends_on:
    - 'postgres'
  environment:
    HASURA_GRAPHQL_DATABASE_URL: postgres://postgres:postgrespassword@postgres:5432
    HASURA_GRAPHQL_ADMIN_SECRET: questionsecretkey
    HASURA_GRAPHQL_JWT_SECRET: '{"type":"RS256","jwk_url": "https://www.googleapis.com/service_accounts/v1/jwk/securetoken@system.gserviceaccount.com","audience": "lightweight-back-office-dev","issuer": "https://securetoken.google.com/lightweight-back-office-dev" }'
```

Second step is to create a http endpoint who verify credential passed in request and build a JWT token who attests users identity. In documentation Hasura gives required properties for JWT token, for instance you have to specify user id and user role. To build and return JWT token I used Firebase Functions:

```tsx
import { adminApp, firebaseApp, func } from '../config';

const express = require('express');

const app = express();
app.use(express.json());

type AuthEntity = {
  username: string;
  password: string;
};

function getCredentialsFromBody(body: any): AuthEntity {
  const {
    input: {
      arg: { username, password },
    },
  } = body;
  return {
    username: username,
    password: password,
  };
}

function getUidFromResponse(body: any): string {
  const {
    user: { uid },
  } = body;
  return uid;
}

function getTokenFromFirebase(auth: AuthEntity): Promise<any> {
  return firebaseApp
    .auth()
    .signInWithEmailAndPassword(auth.username, auth.password);
}

app.post('/', function (req: any, res: any) {
  try {
    const auth = getCredentialsFromBody(req.body);
    getTokenFromFirebase(auth)
      .then((data: any) => {
        const uid = getUidFromResponse(data);
        console.log(`[INFO]: Logged as: ${uid}`);
        if (!uid) res.status(400).json({ msg: 'No uid returned' });
        adminApp
          .auth()
          .createCustomToken(uid)
          .then((customToken: any) => {
            res.status(200).json({ accessToken: customToken });
          })
          .catch((error: any) => {
            res.status(400).json({ msg: `Error on token creation: ${error}` });
          });
      })
      .catch((error: any) => {
        console.log(`[INFO]: Error Loggin: ${error}`);
        res.status(400).json({ msg: error });
      });
  } catch (e) {
    console.log(`[ERROR]: Error in the payload: ${e}`);
    res.status(400).json({ msg: 'Error in the payload' });
  }
});

// Expose Express API as a single Cloud Function:
exports.getToken = func.https.onRequest(app);
```

Next step is to specify which data user role can access. In Hasura console you have a permission tab for each datatable where you could set different restriction for each role. It could be very specify if you want, in my case I have granted access to all tables for the user role.

[Authentication & Authorization | Hasura GraphQL Docs](https://hasura.io/docs/1.0/graphql/core/auth/index.html)

**6) And then ?**

Once your Hasura instance is configure you can fetch data from it GraphQL endpoint. During the development if the domain evolved you can use migration to change your data models and you can add action or event trigger throughout development.
